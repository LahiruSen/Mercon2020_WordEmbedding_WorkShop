{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lahiru_sentiment_analysis_v4.ipynb","provenance":[{"file_id":"1Hw2kDRrR4yBoQtyzRMs_4wdpFYfwZhcD","timestamp":1595649822292}],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"t_69D9XsHwu7","colab_type":"code","colab":{}},"source":["!pip install numpy==1.16.1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cf4oqzjCFAJU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595699240519,"user_tz":-330,"elapsed":2668,"user":{"displayName":"Lahiru Senevirathne","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRzF3KfxeuLmDoDB90oNXQ5_ivLn8-Ar4kecdc=s64","userId":"12627549003426465017"}},"outputId":"bf7f4cfd-5a69-4eca-c723-a3b0e7c054de"},"source":["# MLP for the IMDB problem\n","import numpy as np\n","import keras\n","import pickle \n","from keras.datasets import imdb\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Flatten\n","from keras.layers import Average\n","from keras.layers.embeddings import Embedding\n","from keras.layers.convolutional import Conv1D\n","from keras.layers.convolutional import MaxPooling1D\n","from keras.preprocessing import sequence\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import warnings,logging, os\n","warnings.filterwarnings('ignore')\n","logging.disable(logging.WARNING)\n","os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n","# fix random seed for reproducibility\n","seed = 7\n","np.random.seed(seed)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"NhLbP7mpyD95","colab_type":"code","colab":{}},"source":["# Run this cell to mount your Google Drive.\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","#set below folder path to shared folder on google drive\n","folder_path = '/content/drive/My Drive/University/FYP/Conferences/MerCon/word embedding workshop/copy_WordEmbed workshop/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v37A5HmZyFBH","colab_type":"code","colab":{}},"source":["import sys\n","sys.path.insert(0, folder_path)\n","\n","from utils import *"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"76fOxW7_3MO2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1595699342549,"user_tz":-330,"elapsed":6638,"user":{"displayName":"Lahiru Senevirathne","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRzF3KfxeuLmDoDB90oNXQ5_ivLn8-Ar4kecdc=s64","userId":"12627549003426465017"}},"outputId":"2f333e45-f4b6-4f3b-a3a1-b844c2c7615a"},"source":["# load the dataset but only keep the top n words, zero the rest\n","top_words = 15000\n","(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n","imdb_words = imdb.get_word_index()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n","17465344/17464789 [==============================] - 0s 0us/step\n","Downloading data from https://s3.amazonaws.com/text-datasets/imdb_word_index.json\n","1646592/1641221 [==============================] - 0s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FsMUhxVqtjmn","colab_type":"code","colab":{}},"source":["INDEX_FROM=3\n","word_to_id = {k:(v+INDEX_FROM) for k,v in imdb_words.items()}\n","word_to_id[\"<PAD>\"] = 0\n","word_to_id[\"<START>\"] = 1\n","word_to_id[\"<UNK>\"] = 2\n","MAX_NB_WORDS = 15000\n","embed_dim = 300\n","max_words = 500\n","nb_words = min(MAX_NB_WORDS, len(word_to_id))\n","id_to_word = {value:key for key,value in word_to_id.items()}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4aiyMfBVtziL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1595699351710,"user_tz":-330,"elapsed":962,"user":{"displayName":"Lahiru Senevirathne","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRzF3KfxeuLmDoDB90oNXQ5_ivLn8-Ar4kecdc=s64","userId":"12627549003426465017"}},"outputId":"857c8d45-2ee0-463c-a0e1-ad9b5e82b403"},"source":["[id_to_word[i] for i in X_train[0]]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['<START>',\n"," 'this',\n"," 'film',\n"," 'was',\n"," 'just',\n"," 'brilliant',\n"," 'casting',\n"," 'location',\n"," 'scenery',\n"," 'story',\n"," 'direction',\n"," \"everyone's\",\n"," 'really',\n"," 'suited',\n"," 'the',\n"," 'part',\n"," 'they',\n"," 'played',\n"," 'and',\n"," 'you',\n"," 'could',\n"," 'just',\n"," 'imagine',\n"," 'being',\n"," 'there',\n"," 'robert',\n"," '<UNK>',\n"," 'is',\n"," 'an',\n"," 'amazing',\n"," 'actor',\n"," 'and',\n"," 'now',\n"," 'the',\n"," 'same',\n"," 'being',\n"," 'director',\n"," '<UNK>',\n"," 'father',\n"," 'came',\n"," 'from',\n"," 'the',\n"," 'same',\n"," 'scottish',\n"," 'island',\n"," 'as',\n"," 'myself',\n"," 'so',\n"," 'i',\n"," 'loved',\n"," 'the',\n"," 'fact',\n"," 'there',\n"," 'was',\n"," 'a',\n"," 'real',\n"," 'connection',\n"," 'with',\n"," 'this',\n"," 'film',\n"," 'the',\n"," 'witty',\n"," 'remarks',\n"," 'throughout',\n"," 'the',\n"," 'film',\n"," 'were',\n"," 'great',\n"," 'it',\n"," 'was',\n"," 'just',\n"," 'brilliant',\n"," 'so',\n"," 'much',\n"," 'that',\n"," 'i',\n"," 'bought',\n"," 'the',\n"," 'film',\n"," 'as',\n"," 'soon',\n"," 'as',\n"," 'it',\n"," 'was',\n"," 'released',\n"," 'for',\n"," '<UNK>',\n"," 'and',\n"," 'would',\n"," 'recommend',\n"," 'it',\n"," 'to',\n"," 'everyone',\n"," 'to',\n"," 'watch',\n"," 'and',\n"," 'the',\n"," 'fly',\n"," 'fishing',\n"," 'was',\n"," 'amazing',\n"," 'really',\n"," 'cried',\n"," 'at',\n"," 'the',\n"," 'end',\n"," 'it',\n"," 'was',\n"," 'so',\n"," 'sad',\n"," 'and',\n"," 'you',\n"," 'know',\n"," 'what',\n"," 'they',\n"," 'say',\n"," 'if',\n"," 'you',\n"," 'cry',\n"," 'at',\n"," 'a',\n"," 'film',\n"," 'it',\n"," 'must',\n"," 'have',\n"," 'been',\n"," 'good',\n"," 'and',\n"," 'this',\n"," 'definitely',\n"," 'was',\n"," 'also',\n"," 'congratulations',\n"," 'to',\n"," 'the',\n"," 'two',\n"," 'little',\n"," \"boy's\",\n"," 'that',\n"," 'played',\n"," 'the',\n"," '<UNK>',\n"," 'of',\n"," 'norman',\n"," 'and',\n"," 'paul',\n"," 'they',\n"," 'were',\n"," 'just',\n"," 'brilliant',\n"," 'children',\n"," 'are',\n"," 'often',\n"," 'left',\n"," 'out',\n"," 'of',\n"," 'the',\n"," 'praising',\n"," 'list',\n"," 'i',\n"," 'think',\n"," 'because',\n"," 'the',\n"," 'stars',\n"," 'that',\n"," 'play',\n"," 'them',\n"," 'all',\n"," 'grown',\n"," 'up',\n"," 'are',\n"," 'such',\n"," 'a',\n"," 'big',\n"," 'profile',\n"," 'for',\n"," 'the',\n"," 'whole',\n"," 'film',\n"," 'but',\n"," 'these',\n"," 'children',\n"," 'are',\n"," 'amazing',\n"," 'and',\n"," 'should',\n"," 'be',\n"," 'praised',\n"," 'for',\n"," 'what',\n"," 'they',\n"," 'have',\n"," 'done',\n"," \"don't\",\n"," 'you',\n"," 'think',\n"," 'the',\n"," 'whole',\n"," 'story',\n"," 'was',\n"," 'so',\n"," 'lovely',\n"," 'because',\n"," 'it',\n"," 'was',\n"," 'true',\n"," 'and',\n"," 'was',\n"," \"someone's\",\n"," 'life',\n"," 'after',\n"," 'all',\n"," 'that',\n"," 'was',\n"," 'shared',\n"," 'with',\n"," 'us',\n"," 'all']"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"EhzRaByj3MO5","colab_type":"code","colab":{}},"source":["# maximum words for a review. We truncate longer reviews and pad shorter reviews to make the length 500\n","max_words = 500 \n","X_train = sequence.pad_sequences(X_train, maxlen=max_words, padding='post', truncating='post', value=0.0)\n","X_test = sequence.pad_sequences(X_test, maxlen=max_words, padding='post', truncating='post', value=0.0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R9TcTuK53MO_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":408},"executionInfo":{"status":"ok","timestamp":1595700620181,"user_tz":-330,"elapsed":31092,"user":{"displayName":"Lahiru Senevirathne","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRzF3KfxeuLmDoDB90oNXQ5_ivLn8-Ar4kecdc=s64","userId":"12627549003426465017"}},"outputId":"1db07ecf-94d3-42c6-9f74-f6543d6c3856"},"source":["# This is with random initializations for embeddings\n","model = Sequential()\n","model.add(Embedding(top_words, 300, input_length=max_words,trainable=False))\n","model.add(keras.layers.Lambda(lambda x: keras.backend.mean(x, axis=1)))\n","model.add(Dense(250, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","print(model.summary())\n","\n","# Fit the model\n","model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=2, batch_size=128, verbose=2)\n","# Final evaluation of the model\n","scores = model.evaluate(X_test, y_test, verbose=0)\n","print(\"Accuracy: %.2f%%\" % (scores[1]*100))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_4\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_4 (Embedding)      (None, 500, 300)          4500000   \n","_________________________________________________________________\n","lambda_4 (Lambda)            (None, 300)               0         \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 250)               75250     \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 1)                 251       \n","=================================================================\n","Total params: 4,575,501\n","Trainable params: 75,501\n","Non-trainable params: 4,500,000\n","_________________________________________________________________\n","None\n","Train on 25000 samples, validate on 25000 samples\n","Epoch 1/2\n"," - 12s - loss: 0.6931 - accuracy: 0.5031 - val_loss: 0.6917 - val_accuracy: 0.5342\n","Epoch 2/2\n"," - 12s - loss: 0.6911 - accuracy: 0.5202 - val_loss: 0.6900 - val_accuracy: 0.5036\n","Accuracy: 50.36%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WUfJucg__ykK","colab_type":"text"},"source":["Below snippet loads the model. Would take a couple of minutes."]},{"cell_type":"code","metadata":{"id":"tv-TLYSLp7sf","colab_type":"code","colab":{}},"source":["# #embedding matrix\n","# MAX_NB_WORDS = 15000\n","# embed_dim = 300\n","# max_words = 500\n","# words_not_found = []\n","# nb_words = min(MAX_NB_WORDS, len(word_to_id))\n","# embedding_matrix = np.zeros((nb_words, embed_dim))\n","# for word, i in word_to_id.items():\n","#     if i >= nb_words:\n","#         continue\n","#     embedding_vector = embeddings_index[word]\n","#     if (embedding_vector is not None) and len(embedding_vector) > 0:\n","#         # words not found in embedding index will be all-zeros.\n","#         embedding_matrix[i] = embedding_vector\n","#     else:\n","#         words_not_found.append(word)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ChkjyTkrp3ay","colab_type":"code","colab":{}},"source":["embedding_matrix = load_obj(folder_path + 'sentiment_analysis/embedding_matrix')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1LYabOT6SlOD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":408},"executionInfo":{"status":"ok","timestamp":1595699639471,"user_tz":-330,"elapsed":31612,"user":{"displayName":"Lahiru Senevirathne","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRzF3KfxeuLmDoDB90oNXQ5_ivLn8-Ar4kecdc=s64","userId":"12627549003426465017"}},"outputId":"8b4ea8c9-c10d-4927-eba1-4f252227aad1"},"source":["# This model uses pretrained embeddings, but does not train the embeddings while the model is training.\n","model2 = Sequential()\n","model2.add(Embedding(nb_words, embed_dim, weights=[embedding_matrix], input_length=max_words, trainable=False))\n","model2.add(keras.layers.Lambda(lambda x: keras.backend.mean(x, axis=1)))\n","model2.add(Dense(250, activation='relu'))\n","model2.add(Dense(1, activation='sigmoid'))\n","model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","print(model2.summary())\n","\n","# Fit the model\n","model2.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=2, batch_size=128, verbose=2)\n","# Final evaluation of the model\n","scores2 = model2.evaluate(X_test, y_test, verbose=0)\n","print(\"Accuracy: %.2f%%\" % (scores2[1]*100))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_2 (Embedding)      (None, 500, 300)          4500000   \n","_________________________________________________________________\n","lambda_2 (Lambda)            (None, 300)               0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 250)               75250     \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 1)                 251       \n","=================================================================\n","Total params: 4,575,501\n","Trainable params: 75,501\n","Non-trainable params: 4,500,000\n","_________________________________________________________________\n","None\n","Train on 25000 samples, validate on 25000 samples\n","Epoch 1/2\n"," - 12s - loss: 0.6735 - accuracy: 0.5908 - val_loss: 0.6486 - val_accuracy: 0.6491\n","Epoch 2/2\n"," - 12s - loss: 0.6171 - accuracy: 0.6773 - val_loss: 0.5989 - val_accuracy: 0.7039\n","Accuracy: 70.39%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fIAm66ahm5gz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":408},"executionInfo":{"status":"ok","timestamp":1595699734645,"user_tz":-330,"elapsed":61510,"user":{"displayName":"Lahiru Senevirathne","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRzF3KfxeuLmDoDB90oNXQ5_ivLn8-Ar4kecdc=s64","userId":"12627549003426465017"}},"outputId":"f37b3e44-e199-4c14-afe1-1fa454ebaa7b"},"source":["# This model uses trainable pretrained word embeddings\n","model3 = Sequential()\n","model3.add(Embedding(nb_words, embed_dim, weights=[embedding_matrix], input_length=max_words, trainable=True))\n","model3.add(keras.layers.Lambda(lambda x: keras.backend.mean(x, axis=1)))\n","model3.add(Dense(250, activation='relu'))\n","model3.add(Dense(1, activation='sigmoid'))\n","model3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","print(model3.summary())\n","# Fit the model\n","model3.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=2, batch_size=128, verbose=2)\n","# Final evaluation of the model\n","scores3 = model3.evaluate(X_test, y_test, verbose=0)\n","print(\"Accuracy: %.2f%%\" % (scores3[1]*100))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_3 (Embedding)      (None, 500, 300)          4500000   \n","_________________________________________________________________\n","lambda_3 (Lambda)            (None, 300)               0         \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 250)               75250     \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 1)                 251       \n","=================================================================\n","Total params: 4,575,501\n","Trainable params: 4,575,501\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Train on 25000 samples, validate on 25000 samples\n","Epoch 1/2\n"," - 27s - loss: 0.5197 - accuracy: 0.7410 - val_loss: 0.3350 - val_accuracy: 0.8684\n","Epoch 2/2\n"," - 27s - loss: 0.2528 - accuracy: 0.9022 - val_loss: 0.2802 - val_accuracy: 0.8868\n","Accuracy: 88.68%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Zx0WT6wOHLeQ","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}